{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow NMT implementation: Will Cover \n",
    "- bi-direction GRU\n",
    "- Attention Model\n",
    "- Language Model\n",
    "- Highway Networks (Probably)\n",
    "- Tensorboard Functionalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Change this ipynb into a project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from nmt_utils.helper import data_helper\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() #Clears the default graph stack and resets the global default graph.\n",
    "sess = tf.InteractiveSession() #initializes a tensorflow session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class opt:\n",
    "    #source_vocab_size = None,\n",
    "    #dest_vocab_size  =None,\n",
    "    source_embedding_size = 1000\n",
    "    dest_embedding_size = 1000\n",
    "    source_training_file = \"/media/user/069A453E9A452B8D/Ram/projectsData/nmt/train.en\"\n",
    "    dest_training_file = \"/media/user/069A453E9A452B8D/Ram/projectsData/nmt/train.vi\"\n",
    "    source_val_file = \"/media/user/069A453E9A452B8D/Ram/projectsData/nmt/tst2012.en\"\n",
    "    dest_val_file = \"/media/user/069A453E9A452B8D/Ram/projectsData/nmt/tst2012.vi\"\n",
    "    source_vocab_file = \"/media/user/069A453E9A452B8D/Ram/projectsData/nmt/vocab.en\"\n",
    "    dest_vocab_file = \"/media/user/069A453E9A452B8D/Ram/projectsData/nmt/vocab.vi\"\n",
    "    log_dir=\"tmp/ckpt1/\"\n",
    "    \n",
    "#     source_max_length = None\n",
    "#     dest_max_length = None    \n",
    "#     source_vocab_size= None\n",
    "#     dest_vocab_size=None\n",
    "    batch_size = 4\n",
    "#     source_vocab= None\n",
    "#     dest_vocab = None\n",
    "    \n",
    "    #encoder_hidden_units = 2\n",
    "    encoder_hiddent_units_size = [256,256]\n",
    "    #decoder_hidden_units = 2\n",
    "    decoder_hidden_units_size = [512, 256]\n",
    "    \n",
    "    share_vocab = False\n",
    "    time_major = False\n",
    "    encoder_state_to_decoder = False\n",
    "    attention_depth = 256 ## attention Ai\n",
    "    attention_layer_size = 128 ###\n",
    "    \n",
    "    mode = \"train\" ## or \"infer\"\n",
    "    \n",
    "    optimizer = \"Adam\" #or \"SGD\"\n",
    "    nepochs = 10\n",
    "    val_epoch  = 2 #every 2 epoch\n",
    "    save_sess_epoch = 5 #every  \n",
    "    \n",
    "data = data_helper(opt)   \n",
    "\n",
    "UNK = \"<unk>\"\n",
    "SOS = \"<s>\"\n",
    "EOS = \"</s>\"\n",
    "UNK_ID = 0\n",
    "\n",
    "#opt.source_vocab_file, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EMBEDDINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('placeholders') as scope:\n",
    "    encoder_inputs = tf.placeholder(shape=(None, None), dtype=tf.int32, name='encoder_inputs')\n",
    "    encoder_inputs_length = tf.placeholder(shape=(None,), dtype=tf.int32, name='encoder_inputs_length')\n",
    "\n",
    "    decoder_targets = tf.placeholder(shape=(None, None), dtype=tf.int32, name='decoder_targets')\n",
    "    decoder_targets_length = tf.placeholder(shape=(None,), dtype=tf.int32, name='decoder_targets_length')\n",
    "    \n",
    "    #source_start_token = tf.placeholder(shape=(1,), dtype=tf.int32, name='start_token')\n",
    "    #source_end_token = tf.palceholder(shape=(1,), dtype=tf.int32, name='end_token')\n",
    "    \n",
    "    #dest_start_token = tf.placeholder(shape=(1,), dtype=tf.int32, name='start_token')\n",
    "    #dest_end_token = tf.placeholder(shape=(1,), dtype=tf.int32, name='end_token')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source_max_length = None\n",
    "# dest_max_length = None    \n",
    "\n",
    "# source_vocab_size= None\n",
    "# dest_vocab_size=None\n",
    "\n",
    "# batch_size = None\n",
    "\n",
    "# source_vocab= None\n",
    "# dest_vocab = None\n",
    "\n",
    "source_max_length, _ = tf.unstack(tf.shape(encoder_inputs))\n",
    "dest_max_length, _ = tf.unstack(tf.shape(decoder_targets))\n",
    "\n",
    "source_vocab, source_vocab_size = data.load_vocab(opt.source_vocab_file)\n",
    "dest_vocab, dest_vocab_size = data.load_vocab(opt.dest_vocab_file)\n",
    "\n",
    "src_lookup_table, dest_lookup_table = data.create_vocab_tables()\n",
    "\n",
    "dest_start_token = [tf.cast(dest_lookup_table.lookup(tf.constant(SOS)), tf.int32)]\n",
    "dest_end_token = [tf.cast(dest_lookup_table.lookup(tf.constant(EOS)), tf.int32)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"embed\") as scope:\n",
    "    input_embeddings = tf.contrib.layers.embed_sequence(encoder_inputs, vocab_size = source_vocab_size,\n",
    "                                embed_dim=opt.source_embedding_size)\n",
    "    \n",
    "    decoder_targets_embeddings = tf.contrib.layers.embed_sequence(decoder_targets, \n",
    "                                                                  vocab_size = dest_vocab_size,\n",
    "                                                                  embed_dim = opt.dest_embedding_size, \n",
    "                                                                  scope = \"decoder_embeddings\")\n",
    "    \n",
    "    if opt.time_major:\n",
    "        print(\"Time Major: True\")\n",
    "        input_embeddings = input_embeddings.swapaxes(0, 1) ## Change  Batch Major  to Time Major\n",
    "        decoder_targets_embeddings = decoder_targets_embeddings.swapaxes(0, 1)\n",
    "\n",
    "    \n",
    "    with tf.variable_scope(\"decoder_embeddings\", reuse = True):\n",
    "        decoder_embeddings_mat = tf.get_variable(\"embeddings\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('encoder') as scope:\n",
    "    inputs_to_next = input_embeddings\n",
    "    encoder_fw_cells = []\n",
    "    encoder_bw_cells = []\n",
    "    \n",
    "    index = 0\n",
    "    for units in opt.encoder_hiddent_units_size:\n",
    "        with tf.variable_scope(\"encoder_fw_\"+str(index)):\n",
    "            encoder_fw_cells.append(tf.nn.rnn_cell.GRUCell(num_units = units)) # name = \"encoder_fw_\"+str(index) \n",
    "                                                                            # supported in tf1.6 maybe 1.5 also\n",
    "        with tf.variable_scope(\"encoder_bw_\"+str(index)):                                                                   \n",
    "            encoder_bw_cells.append(tf.nn.rnn_cell.GRUCell(num_units = units)) # name = \"encoder_bw_\"+str(index)\n",
    "        index = index + 1\n",
    "    \n",
    "    for index in range(len(opt.encoder_hiddent_units_size)):\n",
    "        with tf.variable_scope(\"encoder_bidi_\"+str(index)):\n",
    "            ((encoder_fw_outputs,\n",
    "                  encoder_bw_outputs),\n",
    "             (encoder_fw_final_state,\n",
    "                  encoder_bw_final_state)) = tf.nn.bidirectional_dynamic_rnn(cell_fw=encoder_fw_cells[index],\n",
    "                                                        cell_bw=encoder_bw_cells[index],\n",
    "                                                        inputs=inputs_to_next,\n",
    "                                                        sequence_length=encoder_inputs_length,\n",
    "                                                        dtype=tf.float32, time_major=opt.time_major,\n",
    "                                                        scope = \"encoder_bidi_rnn\"+str(index))\n",
    "        \n",
    "        inputs_to_next = tf.concat((encoder_fw_outputs,encoder_bw_outputs),2)\n",
    "\n",
    "\n",
    "    encoder_outputs = inputs_to_next\n",
    "    encoder_final_state = tf.concat((encoder_fw_final_state, encoder_bw_final_state), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About GRUcells and sharing weights\n",
    "\n",
    "name: String, the name of the layer. Layers with the same name will share weights, but to avoid mistakes we require reuse=True in such cases.\n",
    "\n",
    "### For LSTM: encoder outputs will be      \n",
    "     encoder_final_state_c = tf.concat(\n",
    "                     (encoder_fw_final_state.c, encoder_bw_final_state.c), 1)\n",
    "\n",
    "     encoder_final_state_h = tf.concat(\n",
    "                     (encoder_fw_final_state.h, encoder_bw_final_state.h), 1)\n",
    "\n",
    "     #TF Tuple used by LSTM Cells for state_size, zero_state, and output state.\n",
    "     encoder_final_state = tf.nn.rnn_cell.LSTMStateTuple(\n",
    "                                 c=encoder_final_state_c,\n",
    "                                 h=encoder_final_state_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(helper, reuse = None):\n",
    "    with tf.variable_scope(\"decoder\", reuse = reuse) as scope:\n",
    "\n",
    "        decoder_cells = []\n",
    "\n",
    "        index  = 0\n",
    "        for units in opt.decoder_hidden_units_size:\n",
    "            with tf.variable_scope(\"decoder_cell_\"+str(index)):\n",
    "                decoder_cells.append(tf.nn.rnn_cell.GRUCell(num_units = units)) #name = \"decoder_cell_\"+str(index)\n",
    "            index = index + 1\n",
    "\n",
    "        decoder_stack = tf.nn.rnn_cell.MultiRNNCell(decoder_cells)\n",
    "\n",
    "        attention_mechanism = tf.contrib.seq2seq.LuongAttention(num_units=opt.attention_depth, \n",
    "                                                                memory=encoder_outputs,\n",
    "                                                                memory_sequence_length=None)  #TODO:  adjust memory_sequence_length \n",
    "        attn_cell = tf.contrib.seq2seq.AttentionWrapper(\n",
    "                    decoder_stack, attention_mechanism, alignment_history = False,\n",
    "                   attention_layer_size=opt.attention_layer_size) ##TODO: alignment_history = False\n",
    "\n",
    "        out_cell = tf.contrib.rnn.OutputProjectionWrapper(\n",
    "                    attn_cell, dest_vocab_size, reuse=reuse)\n",
    "\n",
    "        decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "                    out_cell, helper=helper,\n",
    "                    initial_state=out_cell.zero_state(\n",
    "                        dtype=tf.float32, batch_size=opt.batch_size))\n",
    "\n",
    "\n",
    "        outputs = tf.contrib.seq2seq.dynamic_decode(\n",
    "                    decoder=decoder, output_time_major=opt.time_major,\n",
    "                    impute_finished=True, maximum_iterations=None)         #maximum_iterations=dest_max_length\n",
    "        return outputs[0]    ##final_outputs, final_state, final_sequence_lengths\n",
    "        \n",
    "train_helper = tf.contrib.seq2seq.TrainingHelper(decoder_targets_embeddings, \n",
    "                                                 decoder_targets_length, time_major=opt.time_major)\n",
    "\n",
    "#batch_size = tf.unstack(tf.shape()) ## TODO\n",
    "start_tokens =  tf.fill(tf.cast([opt.batch_size], tf.int32), dest_start_token[0])\n",
    "start_tokens = tf.Print(start_tokens, start_tokens, message=\"Start_Tokens: \", first_n=2)\n",
    "infer_helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(decoder_embeddings_mat, \n",
    "                                                        start_tokens=start_tokens, end_token=dest_end_token[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The encoder doesn't need GO & you can merge EOS & PAD (as long as sequence lengths are correct). \n",
    "# Here are an example with a batch of 2 sentences for training:\n",
    "# (a) Encoder inputs (encoder lengths = [3, 2]):\n",
    "# a b c EOS\n",
    "# d e EOS EOS\n",
    "# (b) Decoder inputs (decoder lengths = [4, 3]):\n",
    "# GO 1 2 3\n",
    "# GO 4 5 EOS\n",
    "# (c) Decoder outputs (shift-by-1 of decoder inputs):\n",
    "# 1 2 3 EOS\n",
    "# 4 5 EOS EOS\n",
    "# (the first EOS is part of the loss)\n",
    "\n",
    "# During inference: we only have (a) + GO symbol fed to GreedyEmbeddingHelper, \n",
    "#so it's important to make sure this GO is the same as the GO in (b).\n",
    "\n",
    "\n",
    "def get_src_tgt_datasaet(src_dataset,\n",
    "                 dest_dataset,\n",
    "                 src_lookup_table,\n",
    "                 dest_lookup_table,\n",
    "                 batch_size,\n",
    "                 #src_max_len=None,\n",
    "                 #dest_max_len=None,\n",
    "                 num_parallel_calls = 4,\n",
    "                 reshuffle_each_iteration=True,\n",
    "                 buffer_size = None):\n",
    "    \n",
    "    if not buffer_size:\n",
    "        buffer_size = batch_size*1000\n",
    "        \n",
    "    src_tgt_dataset = tf.data.Dataset.zip((src_dataset, dest_dataset))\n",
    "    src_tgt_dataset = src_tgt_dataset.map(\n",
    "            lambda src,dest: (tf.string_split([src]).values, tf.string_split([dest]).values),\n",
    "            num_parallel_calls = num_parallel_calls\n",
    "                ).prefetch(buffer_size)\n",
    "    \n",
    "    src_tgt_dataset = src_tgt_dataset.map(\n",
    "            lambda src,dest:(tf.cast(src_lookup_table.lookup(src),tf.int32),\n",
    "                             tf.cast(dest_lookup_table.lookup(dest),tf.int32)), \n",
    "            num_parallel_calls = num_parallel_calls\n",
    "                ).prefetch(buffer_size)\n",
    "    \n",
    "    \n",
    "    src_eos_id = tf.cast(src_lookup_table.lookup(tf.constant(EOS)), tf.int32)\n",
    "    dest_eos_id = tf.cast(dest_lookup_table.lookup(tf.constant(EOS)), tf.int32)\n",
    "    dest_sos_id = tf.cast(dest_lookup_table.lookup(tf.constant(SOS)), tf.int32)\n",
    "    \n",
    "    src_tgt_dataset = src_tgt_dataset.map(\n",
    "            lambda src,dest:(tf.concat((src, [src_eos_id]), 0),\n",
    "                            tf.concat(([dest_sos_id], dest, [dest_eos_id]), 0)), \n",
    "            num_parallel_calls = num_parallel_calls\n",
    "                ).prefetch(buffer_size)\n",
    "    \n",
    "    src_tgt_dataset = src_tgt_dataset.map(\n",
    "            lambda src,dest:( {'src':  src, 'dest': dest, 'src_len': [tf.size(src)], 'dest_len':[tf.size(dest)]}), \n",
    "            num_parallel_calls = num_parallel_calls\n",
    "                ).prefetch(buffer_size)\n",
    "    \n",
    "    src_tgt_dataset = src_tgt_dataset.repeat(10)   ##TODO: for now repeat for 10 epochs \n",
    "    src_tgt_dataset = src_tgt_dataset.shuffle(buffer_size)\n",
    "    src_tgt_dataset = src_tgt_dataset.padded_batch(batch_size, \n",
    "                                        padded_shapes={'src': [None], 'dest': [None], 'src_len':[None], 'dest_len':[None]},           \n",
    "                                        padding_values = {'src': src_eos_id, 'dest': dest_eos_id, 'src_len':0, 'dest_len':0})\n",
    "    \n",
    "    return src_tgt_dataset\n",
    "    \n",
    "\n",
    "def get_reinitializable_iterator(src_tgt_dataset):\n",
    "    return tf.data.Iterator.from_structure(src_tgt_dataset.output_types, src_tgt_dataset.output_shapes)\n",
    "\n",
    "#training_init_op = iterator.make_initializer(training_dataset)\n",
    "#validation_init_op = iterator.make_initializer(validation_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dest_eos_id = tf.cast(dest_lookup_table.lookup(tf.constant(EOS)), tf.int32)\n",
    "dest_sos_id = tf.cast(dest_lookup_table.lookup(tf.constant(SOS)), tf.int32)\n",
    "\n",
    "src_train_dataset = tf.data.TextLineDataset(opt.source_training_file)\n",
    "dest_train_dataset = tf.data.TextLineDataset(opt.dest_training_file)\n",
    "\n",
    "src_val_dataset  = tf.data.TextLineDataset(opt.source_val_file)\n",
    "dest_val_dataset = tf.data.TextLineDataset(opt.dest_val_file)\n",
    "\n",
    "training_dataset = get_src_tgt_datasaet(src_train_dataset, dest_train_dataset, src_lookup_table, dest_lookup_table, batch_size=opt.batch_size)\n",
    "validation_dataset = get_src_tgt_datasaet(src_val_dataset, dest_val_dataset, src_lookup_table, dest_lookup_table, batch_size=opt.batch_size)\n",
    "\n",
    "iterator = get_reinitializable_iterator(training_dataset)\n",
    "next_element = next_element = iterator.get_next() \n",
    "\n",
    "training_init_op = iterator.make_initializer(training_dataset)\n",
    "validation_init_op = iterator.make_initializer(validation_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINING and VALIDATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.sequence_mask([1, 3, 2], 5)  <br />\n",
    "[[True, False, False, False, False], \n",
    "[True, True, True, False, False],\n",
    "[True, True, False, False, False]]\n",
    "                                \n",
    "seq2seq_outputs = sess.run(training_decoder_outputs, feeding_dict) <br />\n",
    "np.argmax(seq2seq_outputs.rnn_output[0][0]) = seq2seq_outputs.sample_id[0][0]                          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TensorBoard Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_decoder_outputs = decoder(train_helper)\n",
    "infer_decoder_outputs = decoder(infer_helper, reuse=True)\n",
    "\n",
    "with tf.variable_scope(\"loss\"):\n",
    "    targets_ = tf.gather(decoder_targets,  list(range(1,decoder_targets.shape[1])), axis=1)\n",
    "    end_tokens =  tf.fill(tf.cast([opt.batch_size], tf.int32), dest_end_token[0])\n",
    "    targets = tf.concat([targets_, tf.expand_dims(end_tokens, 1)], 1) \n",
    "    weights = tf.to_float(tf.sequence_mask(decoder_targets_length, decoder_targets[1]))\n",
    "    loss_op = tf.contrib.seq2seq.sequence_loss(\n",
    "                training_decoder_outputs.rnn_output, targets, weights)\n",
    "    tf.summary.scalar(\"loss\", loss_op)\n",
    "    \n",
    "with tf.variable_scope(\"accuracy\"):\n",
    "    with tf.variable_scope(\"train_acc\"):\n",
    "        train_correct_predictios = tf.equal(decoder_targets, training_decoder_outputs.sample_id)\n",
    "        train_accuracy_op = tf.reduce_mean(train_correct_predictions)\n",
    "        tf.summary.scalar(\"train_accuracy\", train_accuracy_op)\n",
    "    \n",
    "    with tf.variable_scope(\"val_acc\"):\n",
    "        val_correct_predictions = tf.equal(decoder_targets, infer_decoder_outputs.sample_id)\n",
    "        val_accuracy_op  = tf.reduce_mean(val_correct_predictions)\n",
    "        tf.summary.scalar(\"val_accuracy\", val_accuracy_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"train_op\"):\n",
    "    assert opt.optimizer == \"Adam\" or opt.optimizer == \"SGD\"\n",
    "    if opt.optimizer == \"Adam\":\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-08)\n",
    "    elif opt.optimizer == \"SGD\":\n",
    "        optimizer = tf.train.MomentumOptimizer(learning_rate = 0.001, momentum = 0.9,  use_nesterov= True)\n",
    "    \n",
    "    train_op = tf.contrib.layers.optimize_loss(\n",
    "                loss, tf.train.get_global_step(),\n",
    "                optimizer=optimizer\n",
    "                learning_rate=None,\n",
    "                summaries=['loss', 'learning_rate'],\n",
    "                learning_rate_decay_fn=None,\n",
    "        \n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = tf.summary.FileWriter(opt.log_dir)\n",
    "writer.add_graph(sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(tf.tables_initializer())\n",
    "\n",
    "for epoch in tqdm(range(opt))\n",
    "sess.run(training_init_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_batch = sess.run(next_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "feeding_dict = {\n",
    "    encoder_inputs: data_batch['src'],\n",
    "    encoder_inputs_length : data_batch['src_len'][:,0],\n",
    "    decoder_targets: data_batch['dest'],\n",
    "    decoder_targets_length: data_batch['dest_len'][:,0],\n",
    "    #dest_start_token: np.array(dest_sos_id),\n",
    "    #dest_end_token: np.array(dest_eos_id)\n",
    "}\n",
    "\n",
    "seq2seq_outputs = sess.run(training_decoder_outputs, feeding_dict)\n",
    "# np.argmax(seq2seq_outputs.rnn_output[0][0]) = seq2seq_outputs.sample_id[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.sequence_mask([1, 3, 2], 5)  # [[True, False, False, False, False],\n",
    "                                #  [True, True, True, False, False],\n",
    "                                #  [True, True, False, False, False]]\n",
    "        \n",
    "# add  accuracy for validation\n",
    "\n",
    "# add regularization in loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
