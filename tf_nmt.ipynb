{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow NMT implementation: Will Cover \n",
    "- bi-direction GRU\n",
    "- Attention Model\n",
    "- Language Model\n",
    "- Highway Networks (Probably)\n",
    "- Tensorboard Functionalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Change this ipynb into a project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from nmt_utils.helper import data_helper\n",
    "from tqdm import tqdm\n",
    "tqdm.monitor_interval = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() #Clears the default graph stack and resets the global default graph.\n",
    "sess = tf.InteractiveSession() #initializes a tensorflow session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class opt:\n",
    "    #source_vocab_size = None,\n",
    "    #dest_vocab_size  =None,\n",
    "    source_embedding_size = 300\n",
    "    dest_embedding_size = 300\n",
    "    source_training_file = \"/mnt/069A453E9A452B8D/Ram/projectsData/nmt/train.en\"\n",
    "    dest_training_file = \"/mnt/069A453E9A452B8D/Ram/projectsData/nmt/train.vi\"\n",
    "    source_val_file = \"/mnt/069A453E9A452B8D/Ram/projectsData/nmt/tst2012.en\"\n",
    "    dest_val_file = \"/mnt/069A453E9A452B8D/Ram/projectsData/nmt/tst2012.vi\"\n",
    "    source_vocab_file = \"/mnt/069A453E9A452B8D/Ram/projectsData/nmt/vocab.en\"\n",
    "    dest_vocab_file = \"/mnt/069A453E9A452B8D/Ram/projectsData/nmt/vocab.vi\"\n",
    "    log_dir=\"/mnt/069A453E9A452B8D/Ram/projectsData/nmt/tmp/ckpt1/\"\n",
    "    \n",
    "#     source_max_length = None\n",
    "#     dest_max_length = None    \n",
    "#     source_vocab_size= None\n",
    "#     dest_vocab_size=None\n",
    "    batch_size = 16\n",
    "#    val_batch_size=1\n",
    "#     source_vocab= None\n",
    "#     dest_vocab = None\n",
    "    \n",
    "    #encoder_hidden_units = 2\n",
    "    encoder_hiddent_units_size = [256,256]\n",
    "    #decoder_hidden_units = 2\n",
    "    decoder_hidden_units_size = [512, 256]\n",
    "    \n",
    "    share_vocab = False\n",
    "    time_major = False\n",
    "    encoder_state_to_decoder = False\n",
    "    attention_depth = 256 ## attention Ai\n",
    "    attention_layer_size = 128 ###\n",
    "    \n",
    "    mode = \"train\" ## or \"infer\"\n",
    "    \n",
    "    optimizer = \"Adam\" #or \"SGD\"\n",
    "    nepochs = 50\n",
    "    val_epoch  = 5 #every 2 epoch\n",
    "    save_sess_epoch = 5 #every  \n",
    "    \n",
    "data = data_helper(opt)   \n",
    "\n",
    "UNK = \"<unk>\"\n",
    "SOS = \"<s>\"\n",
    "EOS = \"</s>\"\n",
    "UNK_ID = 0\n",
    "\n",
    "#opt.source_vocab_file, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EMBEDDINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('placeholders') as scope:\n",
    "    encoder_inputs = tf.placeholder(shape=(None, None), dtype=tf.int32, name='encoder_inputs')\n",
    "    encoder_inputs_length = tf.placeholder(shape=(None,), dtype=tf.int32, name='encoder_inputs_length')\n",
    "\n",
    "    decoder_targets = tf.placeholder(shape=(None, None), dtype=tf.int32, name='decoder_targets')\n",
    "    decoder_targets_length = tf.placeholder(shape=(None,), dtype=tf.int32, name='decoder_targets_length')\n",
    "    \n",
    "    #source_start_token = tf.placeholder(shape=(1,), dtype=tf.int32, name='start_token')\n",
    "    #source_end_token = tf.palceholder(shape=(1,), dtype=tf.int32, name='end_token')\n",
    "    \n",
    "    #dest_start_token = tf.placeholder(shape=(1,), dtype=tf.int32, name='start_token')\n",
    "    #dest_end_token = tf.placeholder(shape=(1,), dtype=tf.int32, name='end_token')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#source_max_length, dynamic_batch_size = tf.unstack(tf.shape(encoder_inputs))\n",
    "#dest_max_length, _ = tf.unstack(tf.shape(decoder_targets))    NOTE: THIS IS FOR TIME MAJOR THING\n",
    "\n",
    "source_vocab, source_vocab_size = data.load_vocab(opt.source_vocab_file)\n",
    "dest_vocab, dest_vocab_size = data.load_vocab(opt.dest_vocab_file)\n",
    "\n",
    "src_lookup_table, dest_lookup_table = data.create_vocab_tables()\n",
    "\n",
    "dest_start_token = [tf.cast(dest_lookup_table.lookup(tf.constant(SOS)), tf.int32)]\n",
    "dest_end_token = [tf.cast(dest_lookup_table.lookup(tf.constant(EOS)), tf.int32)]\n",
    "\n",
    "start_tokens =  tf.fill(tf.cast([opt.batch_size], tf.int32), dest_start_token[0])\n",
    "decoder_targets_input = tf.concat([tf.expand_dims(start_tokens, 1), decoder_targets], 1)   ## TODO: Refactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"embed\") as scope:\n",
    "    input_embeddings = tf.contrib.layers.embed_sequence(encoder_inputs, vocab_size = source_vocab_size,\n",
    "                                embed_dim=opt.source_embedding_size)\n",
    "    \n",
    "    decoder_targets_embeddings = tf.contrib.layers.embed_sequence(decoder_targets_input, \n",
    "                                                                  vocab_size = dest_vocab_size,\n",
    "                                                                  embed_dim = opt.dest_embedding_size, \n",
    "                                                                  scope = \"decoder_embeddings\")\n",
    "    \n",
    "    if opt.time_major:\n",
    "        print(\"Time Major: True\")\n",
    "        input_embeddings = input_embeddings.swapaxes(0, 1) ## Change  Batch Major  to Time Major\n",
    "        decoder_targets_embeddings = decoder_targets_embeddings.swapaxes(0, 1)\n",
    "\n",
    "    \n",
    "    with tf.variable_scope(\"decoder_embeddings\", reuse = True):\n",
    "        decoder_embeddings_mat = tf.get_variable(\"embeddings\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('encoder') as scope:\n",
    "    inputs_to_next = input_embeddings\n",
    "    encoder_fw_cells = []\n",
    "    encoder_bw_cells = []\n",
    "    \n",
    "    index = 0\n",
    "    for units in opt.encoder_hiddent_units_size:\n",
    "        with tf.variable_scope(\"encoder_fw_\"+str(index)):\n",
    "            encoder_fw_cells.append(tf.nn.rnn_cell.GRUCell(num_units = units)) # name = \"encoder_fw_\"+str(index) \n",
    "                                                                            # supported in tf1.6 maybe 1.5 also\n",
    "        with tf.variable_scope(\"encoder_bw_\"+str(index)):                                                                   \n",
    "            encoder_bw_cells.append(tf.nn.rnn_cell.GRUCell(num_units = units)) # name = \"encoder_bw_\"+str(index)\n",
    "        index = index + 1\n",
    "    \n",
    "    for index in range(len(opt.encoder_hiddent_units_size)):\n",
    "        with tf.variable_scope(\"encoder_bidi_\"+str(index)):\n",
    "            ((encoder_fw_outputs,\n",
    "                  encoder_bw_outputs),\n",
    "             (encoder_fw_final_state,\n",
    "                  encoder_bw_final_state)) = tf.nn.bidirectional_dynamic_rnn(cell_fw=encoder_fw_cells[index],\n",
    "                                                        cell_bw=encoder_bw_cells[index],\n",
    "                                                        inputs=inputs_to_next,\n",
    "                                                        sequence_length=encoder_inputs_length,\n",
    "                                                        dtype=tf.float32, time_major=opt.time_major,\n",
    "                                                        scope = \"encoder_bidi_rnn\"+str(index))\n",
    "        \n",
    "        inputs_to_next = tf.concat((encoder_fw_outputs,encoder_bw_outputs),2)\n",
    "\n",
    "\n",
    "    encoder_outputs = inputs_to_next\n",
    "    encoder_final_state = tf.concat((encoder_fw_final_state, encoder_bw_final_state), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About GRUcells and sharing weights\n",
    "\n",
    "name: String, the name of the layer. Layers with the same name will share weights, but to avoid mistakes we require reuse=True in such cases.\n",
    "\n",
    "### For LSTM: encoder outputs will be      \n",
    "     encoder_final_state_c = tf.concat(\n",
    "                     (encoder_fw_final_state.c, encoder_bw_final_state.c), 1)\n",
    "\n",
    "     encoder_final_state_h = tf.concat(\n",
    "                     (encoder_fw_final_state.h, encoder_bw_final_state.h), 1)\n",
    "\n",
    "     #TF Tuple used by LSTM Cells for state_size, zero_state, and output state.\n",
    "     encoder_final_state = tf.nn.rnn_cell.LSTMStateTuple(\n",
    "                                 c=encoder_final_state_c,\n",
    "                                 h=encoder_final_state_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(helper, reuse = None):\n",
    "    with tf.variable_scope(\"decoder\", reuse = reuse) as scope:\n",
    "\n",
    "        decoder_cells = []\n",
    "\n",
    "        index  = 0\n",
    "        for units in opt.decoder_hidden_units_size:\n",
    "            with tf.variable_scope(\"decoder_cell_\"+str(index)):\n",
    "                decoder_cells.append(tf.nn.rnn_cell.GRUCell(num_units = units)) #name = \"decoder_cell_\"+str(index)\n",
    "            index = index + 1\n",
    "\n",
    "        decoder_stack = tf.nn.rnn_cell.MultiRNNCell(decoder_cells)\n",
    "\n",
    "        attention_mechanism = tf.contrib.seq2seq.LuongAttention(num_units=opt.attention_depth, \n",
    "                                                                memory=encoder_outputs,\n",
    "                                                                memory_sequence_length=encoder_inputs_length)  #TODO:  adjust memory_sequence_length \n",
    "        attn_cell = tf.contrib.seq2seq.AttentionWrapper(\n",
    "                    decoder_stack, attention_mechanism, alignment_history = False,\n",
    "                   attention_layer_size=opt.attention_layer_size) ##TODO: alignment_history = False\n",
    "\n",
    "        out_cell = tf.contrib.rnn.OutputProjectionWrapper(\n",
    "                    attn_cell, dest_vocab_size, reuse=reuse)\n",
    "        \n",
    "        \n",
    "        \n",
    "        decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "                    out_cell, helper=helper,\n",
    "                    initial_state=out_cell.zero_state(\n",
    "                        dtype=tf.float32, batch_size=opt.batch_size))   ##TODO: Use Variable Batch size given of data by using Tf_stack\n",
    "\n",
    "\n",
    "        outputs = tf.contrib.seq2seq.dynamic_decode(\n",
    "                    decoder=decoder, output_time_major=opt.time_major,\n",
    "                    impute_finished=True, maximum_iterations=None)         #maximum_iterations=dest_max_length\n",
    "        return outputs[0]    ##final_outputs, final_state, final_sequence_lengths\n",
    "        \n",
    "train_helper = tf.contrib.seq2seq.TrainingHelper(decoder_targets_embeddings, \n",
    "                                                 decoder_targets_length, time_major=opt.time_major)\n",
    "\n",
    "#batch_size = tf.unstack(tf.shape()) ## TODO\n",
    "#start_tokens = tf.Print(start_tokens, [start_tokens], message=\"Start_Tokens: \", first_n=2)\n",
    "infer_helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(decoder_embeddings_mat, \n",
    "                                                        start_tokens=start_tokens, end_token=dest_end_token[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The encoder doesn't need GO & you can merge EOS & PAD (as long as sequence lengths are correct). \n",
    "# Here are an example with a batch of 2 sentences for training:\n",
    "# (a) Encoder inputs (encoder lengths = [3, 2]):\n",
    "# a b c EOS\n",
    "# d e EOS EOS\n",
    "# (b) Decoder inputs (decoder lengths = [4, 3]):\n",
    "# GO 1 2 3\n",
    "# GO 4 5 EOS\n",
    "# (c) Decoder outputs (shift-by-1 of decoder inputs):\n",
    "# 1 2 3 EOS\n",
    "# 4 5 EOS EOS\n",
    "# (the first EOS is part of the loss)\n",
    "\n",
    "# During inference: we only have (a) + GO symbol fed to GreedyEmbeddingHelper, \n",
    "#so it's important to make sure this GO is the same as the GO in (b).\n",
    "\n",
    "\n",
    "def get_src_tgt_datasaet(src_dataset,\n",
    "                 dest_dataset,\n",
    "                 src_lookup_table,\n",
    "                 dest_lookup_table,\n",
    "                 batch_size,\n",
    "                 #src_max_len=None,\n",
    "                 #dest_max_len=None,\n",
    "                 num_parallel_calls = 4,\n",
    "                 reshuffle_each_iteration=True,\n",
    "                 buffer_size = None):\n",
    "    \n",
    "    if not buffer_size:\n",
    "        buffer_size = batch_size*1000\n",
    "        \n",
    "    src_tgt_dataset = tf.data.Dataset.zip((src_dataset, dest_dataset))\n",
    "    src_tgt_dataset = src_tgt_dataset.map(\n",
    "            lambda src,dest: (tf.string_split([src]).values, tf.string_split([dest]).values),\n",
    "            num_parallel_calls = num_parallel_calls\n",
    "                ).prefetch(buffer_size)\n",
    "    \n",
    "    src_tgt_dataset = src_tgt_dataset.map(\n",
    "            lambda src,dest:(tf.cast(src_lookup_table.lookup(src),tf.int32),\n",
    "                             tf.cast(dest_lookup_table.lookup(dest),tf.int32)), \n",
    "            num_parallel_calls = num_parallel_calls\n",
    "                ).prefetch(buffer_size)\n",
    "    \n",
    "    \n",
    "    src_eos_id = tf.cast(src_lookup_table.lookup(tf.constant(EOS)), tf.int32)\n",
    "    dest_eos_id = tf.cast(dest_lookup_table.lookup(tf.constant(EOS)), tf.int32)\n",
    "    dest_sos_id = tf.cast(dest_lookup_table.lookup(tf.constant(SOS)), tf.int32)\n",
    "    \n",
    "    src_tgt_dataset = src_tgt_dataset.map(\n",
    "            lambda src,dest:(tf.concat((src, [src_eos_id]), 0),\n",
    "                            tf.concat(( dest, [dest_eos_id]), 0)),   #tf.concat(([dest_sos_id], dest, [dest_eos_id]), 0)), \n",
    "            num_parallel_calls = num_parallel_calls\n",
    "                ).prefetch(buffer_size)\n",
    "    \n",
    "    src_tgt_dataset = src_tgt_dataset.map(\n",
    "            lambda src,dest:( {'src':  src, 'dest': dest, 'src_len': [tf.size(src)], 'dest_len':[tf.size(dest) + 1]}), ## +1 as start tokens  will be added later  \n",
    "            num_parallel_calls = num_parallel_calls\n",
    "                ).prefetch(buffer_size)\n",
    "    \n",
    "    #src_tgt_dataset = src_tgt_dataset.repeat(opt.nepochs)   ##TODO: for now repeat for 10 epochs \n",
    "    src_tgt_dataset = src_tgt_dataset.shuffle(buffer_size)\n",
    "    src_tgt_dataset = src_tgt_dataset.padded_batch(batch_size, \n",
    "                      padded_shapes={'src': [None], 'dest': [None], 'src_len':[None], 'dest_len':[None]},           \n",
    "                      padding_values = {'src': src_eos_id, 'dest': dest_eos_id, 'src_len':0, 'dest_len':0})\n",
    "    src_tgt_dataset = src_tgt_dataset.filter(lambda dict: tf.equal(tf.shape(dict['src'])[0], opt.batch_size))  ## TO Filter last element\n",
    "    \n",
    "    return src_tgt_dataset\n",
    "    \n",
    "def get_reinitializable_iterator(src_tgt_dataset):\n",
    "    return tf.data.Iterator.from_structure(src_tgt_dataset.output_types, src_tgt_dataset.output_shapes)\n",
    "\n",
    "#training_init_op = iterator.make_initializer(training_dataset)\n",
    "#validation_init_op = iterator.make_initializer(validation_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dest_eos_id = tf.cast(dest_lookup_table.lookup(tf.constant(EOS)), tf.int32)\n",
    "dest_sos_id = tf.cast(dest_lookup_table.lookup(tf.constant(SOS)), tf.int32)\n",
    "\n",
    "src_train_dataset = tf.data.TextLineDataset(opt.source_training_file)\n",
    "dest_train_dataset = tf.data.TextLineDataset(opt.dest_training_file)\n",
    "\n",
    "src_val_dataset  = tf.data.TextLineDataset(opt.source_val_file)\n",
    "dest_val_dataset = tf.data.TextLineDataset(opt.dest_val_file)\n",
    "\n",
    "training_dataset = get_src_tgt_datasaet(src_train_dataset, dest_train_dataset, src_lookup_table, dest_lookup_table, batch_size=opt.batch_size)\n",
    "validation_dataset = get_src_tgt_datasaet(src_val_dataset, dest_val_dataset, src_lookup_table, dest_lookup_table, batch_size=opt.batch_size)\n",
    "\n",
    "iterator = get_reinitializable_iterator(training_dataset)\n",
    "next_element = next_element = iterator.get_next() \n",
    "\n",
    "training_init_op = iterator.make_initializer(training_dataset)\n",
    "validation_init_op = iterator.make_initializer(validation_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINING and VALIDATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.sequence_mask([1, 3, 2], 5)  <br />\n",
    "[[True, False, False, False, False], \n",
    "[True, True, True, False, False],\n",
    "[True, True, False, False, False]]\n",
    "                                \n",
    "seq2seq_outputs = sess.run(training_decoder_outputs, feeding_dict) <br />\n",
    "np.argmax(seq2seq_outputs.rnn_output[0][0]) = seq2seq_outputs.sample_id[0][0]                          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TensorBoard Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_decoder_outputs = decoder(train_helper)\n",
    "infer_decoder_outputs = decoder(infer_helper, reuse=True)\n",
    "\n",
    "\n",
    "end_tokens =  tf.fill(tf.cast([opt.batch_size], tf.int32), dest_end_token[0])\n",
    "targets = tf.concat([decoder_targets, tf.expand_dims(end_tokens, 1)], 1) \n",
    "weights = tf.to_float(tf.sequence_mask(decoder_targets_length))\n",
    "    \n",
    "with tf.variable_scope(\"train_loss\"):\n",
    "#     targets_ = tf.gather(decoder_targets,  list(range(1,decoder_targets.get_shape[1])), axis=1)\n",
    "    train_loss_op = tf.contrib.seq2seq.sequence_loss(\n",
    "                training_decoder_outputs.rnn_output, targets, weights)         # TODO: add regularization in loss\n",
    "    tf.summary.scalar(\"train_loss\", train_loss_op)   \n",
    "    \n",
    "with tf.variable_scope(\"accuracy\"):\n",
    "    with tf.variable_scope(\"train_acc\"):\n",
    "        train_correct_predictions = tf.to_float(tf.equal(targets, training_decoder_outputs.sample_id))\n",
    "        train_accuracy_op = tf.reduce_mean(train_correct_predictions)\n",
    "        tf.summary.scalar(\"train_accuracy\", train_accuracy_op)\n",
    "    \n",
    "    with tf.variable_scope(\"val_acc\"):\n",
    "        val_correct_predictions = tf.to_float(tf.equal(targets, infer_decoder_outputs.sample_id))\n",
    "        val_accuracy_op  = tf.reduce_mean(val_correct_predictions)\n",
    "        tf.summary.scalar(\"val_accuracy\", val_accuracy_op)\n",
    "\n",
    "        \n",
    "summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"train_op\"):\n",
    "    \n",
    "    assert opt.optimizer == \"Adam\" or opt.optimizer == \"SGD\"\n",
    "    if opt.optimizer == \"Adam\":\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-08)\n",
    "    elif opt.optimizer == \"SGD\":\n",
    "        optimizer = tf.train.MomentumOptimizer(learning_rate = 0.001, momentum = 0.9,  use_nesterov= True)\n",
    "    \n",
    "    train_op = tf.contrib.layers.optimize_loss(\n",
    "                train_loss_op, tf.train.get_global_step(),\n",
    "                optimizer=optimizer,\n",
    "                learning_rate=None,\n",
    "                summaries=['loss', 'learning_rate'],\n",
    "                learning_rate_decay_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = tf.summary.FileWriter(opt.log_dir)\n",
    "writer.add_graph(sess.graph)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(tf.tables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feed_dict(data_batch):\n",
    "    return {\n",
    "            encoder_inputs: data_batch['src'],\n",
    "            encoder_inputs_length : data_batch['src_len'][:,0],\n",
    "            decoder_targets: data_batch['dest'],\n",
    "            decoder_targets_length: data_batch['dest_len'][:,0],\n",
    "            #dest_start_token: np.array(dest_sos_id),\n",
    "            #dest_end_token: np.array(dest_eos_id)\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION- Epoch:0, Accuracy: 2.55050199485e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [29:08<23:48:04, 1748.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING- Epoch:0, Loss:4.46639251709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/50 [58:56<23:34:44, 1768.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING- Epoch:1, Loss:3.48488545418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/50 [1:29:33<23:23:10, 1791.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING- Epoch:2, Loss:3.17170906067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4/50 [1:59:19<22:52:15, 1789.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING- Epoch:3, Loss:2.99496054649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [2:29:33<22:26:02, 1794.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING- Epoch:4, Loss:2.87280368805\n",
      "VALIDATION- Epoch:5, Accuracy: 0.182294294238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6/50 [2:59:09<21:53:46, 1791.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING- Epoch:5, Loss:2.77949094772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7/50 [3:31:17<21:37:55, 1811.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING- Epoch:6, Loss:2.70533156395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 8/50 [4:00:58<21:05:09, 1807.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING- Epoch:7, Loss:2.64208102226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 9/50 [4:29:21<20:27:05, 1795.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING- Epoch:8, Loss:2.58888840675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [4:57:34<19:50:19, 1785.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING- Epoch:9, Loss:2.54357790947\n",
      "VALIDATION- Epoch:10, Accuracy: 0.182052657008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [5:25:52<19:15:21, 1777.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING- Epoch:10, Loss:2.50317764282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 12/50 [5:54:18<18:41:57, 1771.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING- Epoch:11, Loss:2.46969151497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 13/50 [6:22:47<18:09:30, 1766.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING- Epoch:12, Loss:2.4396545887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 14/50 [6:50:56<17:36:42, 1761.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING- Epoch:13, Loss:2.41265630722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [7:19:13<17:04:51, 1756.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING- Epoch:14, Loss:2.39068341255\n",
      "VALIDATION- Epoch:15, Accuracy: 0.18397551775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 16/50 [7:47:57<16:34:25, 1754.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING- Epoch:15, Loss:2.37177538872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 17/50 [8:16:25<16:03:38, 1752.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING- Epoch:16, Loss:2.35363793373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 18/50 [8:44:54<15:33:10, 1749.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING- Epoch:17, Loss:2.34153652191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 19/50 [9:13:26<15:02:58, 1747.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING- Epoch:18, Loss:2.3267095089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [9:42:07<14:33:11, 1746.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING- Epoch:19, Loss:2.31593608856\n",
      "VALIDATION- Epoch:20, Accuracy: 0.180582657456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21/50 [10:10:35<14:03:12, 1744.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING- Epoch:20, Loss:2.30325365067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 22/50 [10:39:09<13:33:28, 1743.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING- Epoch:21, Loss:2.29561901093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 23/50 [11:07:47<13:03:55, 1742.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING- Epoch:22, Loss:2.28585195541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 24/50 [11:36:06<12:34:07, 1740.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING- Epoch:23, Loss:2.28052949905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [12:04:34<12:04:34, 1738.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING- Epoch:24, Loss:2.27526497841\n",
      "VALIDATION- Epoch:25, Accuracy: 0.175650075078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 26/50 [12:33:03<11:35:08, 1737.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING- Epoch:25, Loss:2.27855086327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 27/50 [13:01:29<11:05:43, 1736.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING- Epoch:26, Loss:2.27017569542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 28/50 [13:29:38<10:36:08, 1734.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING- Epoch:27, Loss:2.26413249969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 29/50 [13:58:04<10:06:52, 1733.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING- Epoch:28, Loss:2.2627158165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30/50 [14:26:20<9:37:33, 1732.70s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING- Epoch:29, Loss:2.25454735756\n",
      "VALIDATION- Epoch:30, Accuracy: 0.181652337313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31/50 [14:54:49<9:08:26, 1731.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING- Epoch:30, Loss:2.25429129601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 32/50 [15:23:12<8:39:18, 1731.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING- Epoch:31, Loss:2.25177288055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 33/50 [15:51:36<8:10:13, 1730.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING- Epoch:32, Loss:2.249366045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 34/50 [16:19:58<7:41:09, 1729.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING- Epoch:33, Loss:2.25737738609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [16:48:16<7:12:06, 1728.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING- Epoch:34, Loss:2.24265623093\n",
      "VALIDATION- Epoch:35, Accuracy: 0.178119122982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 36/50 [17:16:43<6:43:10, 1727.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING- Epoch:35, Loss:2.24978375435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-70718a4081ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mtrain_data_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_element\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0;34m[\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_feed_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;31m#accuracy.append(accuracy_)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/user/genv/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/user/genv/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/user/genv/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/user/genv/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/user/genv/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(0, opt.nepochs)):\n",
    "    \n",
    "    if epoch % opt.val_epoch == 0:   \n",
    "        sess.run(validation_init_op)\n",
    "        accuracy = []\n",
    "        while True:\n",
    "            try:\n",
    "                val_data_batch = sess.run(next_element)\n",
    "                #accuracy.append(sess.run(val_accuracy_op, get_feed_dict(val_data_batch)))\n",
    "                accuracy.append(sess.run(train_accuracy_op, get_feed_dict(val_data_batch)))\n",
    "                ##TODO: Currently  using trainingDecoder for (not greedy decoder) for validation\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                break \n",
    "        print(\"VALIDATION- Epoch:{}, Accuracy: {}\".format(epoch, sess.run(tf.reduce_mean(tf.constant(accuracy)))))\n",
    "    \n",
    "    if epoch % opt.save_sess_epoch == 0:\n",
    "        saver.save(sess, os.path.join(opt.log_dir, \"model.ckpt\"), epoch)\n",
    "        \n",
    "    sess.run(training_init_op)\n",
    "    #accuracy = []\n",
    "    loss = []\n",
    "    while True:\n",
    "        try:\n",
    "            train_data_batch = sess.run(next_element)\n",
    "            [_, loss_] = sess.run([train_op, train_loss_op], get_feed_dict(train_data_batch))\n",
    "            loss.append(loss_)\n",
    "            #accuracy.append(accuracy_)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break \n",
    "    print(\"TRAINING- Epoch:{}, Loss:{}\".format(epoch, sess.run(tf.reduce_mean(tf.constant(loss)))))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(validation_init_op)\n",
    "val_data_batch = sess.run(next_element)\n",
    "out  = sess.run(training_decoder_outputs, get_feed_dict(val_data_batch))\n",
    "#print(sess.run(infer_decoder_outputs, get_feed_dict(val_data_batch)))\n",
    "\n",
    "#print(sess.run(val_accuracy_op, get_feed_dict(val_data_batch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4893, 3295,    7,  413, 3295,  110, 2247,  267, 3295,   70,    2,\n",
       "          2,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0], dtype=int32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.sample_id[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,   68, 6210,  109, 4296,   46,    2,    2,    2,    2,    2,\n",
       "          2,    2,    2,    2,    2,    2,    2,    2,    2,    2,    2,\n",
       "          2], dtype=int32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data_batch['src'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7], dtype=int32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data_batch['src_len'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seq2seq_outputs = sess.run(training_decoder_outputs, feeding_dict)\n",
    "# np.argmax(seq2seq_outputs.rnn_output[0][0]) = seq2seq_outputs.sample_id[0][0]\n",
    "\n",
    "#tf.sequence_mask([1, 3, 2], 5)  # [[True, False, False, False, False],\n",
    "                                #  [True, True, True, False, False],\n",
    "                                #  [True, True, False, False, False]]\n",
    "        \n",
    "# add  accuracy for validation\n",
    "\n",
    "# TODO: add regularization in loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
